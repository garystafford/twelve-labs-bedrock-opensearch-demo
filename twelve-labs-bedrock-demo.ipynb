{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8cb51d4",
   "metadata": {},
   "source": [
    "# TwelveLabs on Bedrock / OpenSearch Demonstration\n",
    "\n",
    "Code for the Medium blog post, [Multi-Vector Semantic Search: Advanced Video Search with TwelveLabs and Amazon OpenSearch](https://garystafford.medium.com/multi-vector-semantic-search-advanced-video-search-with-twelve-labs-and-amazon-opensearch-7b81ba52c373). How TwelveLabs AI Models and Amazon OpenSearch Serverless enable multi-vector semantic and hybrid search for video content.\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "See README file for prerequisites.\n",
    "\n",
    "**Workflow Diagram**\n",
    "\n",
    "![Architecture](./twelve_labs_on_bedrock.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b650d3ea",
   "metadata": {},
   "source": [
    "## Install Required Python Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e9601",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pip -Uq\n",
    "%pip install -r requirements.txt -Uq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e8f20",
   "metadata": {},
   "source": [
    "### Restart Kernel\n",
    "\n",
    "If first time installing the packages, restart your Jupyter Notebook's kernel before continuing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ec95d4",
   "metadata": {},
   "source": [
    "## Load Environment Variables\n",
    "\n",
    "There are several ways to load your sensitive environment variables. The package, `python-dotenv`, reads key-value pairs from a plain text `.env` file and can set them as environment variables. We are using the `.env` file to store our sensitive variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a57c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Loads variables from .env file\n",
    "\n",
    "AWS_REGION = os.getenv(\"AWS_REGION_MARENGO\")\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_SESSION_TOKEN = os.getenv(\"AWS_SESSION_TOKEN\")\n",
    "S3_VIDEO_STORAGE_BUCKET_MARENGO = os.getenv(\"S3_VIDEO_STORAGE_BUCKET_MARENGO\")\n",
    "\n",
    "OPENSEARCH_ENDPOINT = os.getenv(\"OPENSEARCH_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df2a0f",
   "metadata": {},
   "source": [
    "### Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d1234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the OpenSearch index name\n",
    "INDEX_NAME = \"tv-commercials-index\"\n",
    "\n",
    "# Set the local directories for OpenSearch documents\n",
    "DOCUMENT_DIRECTORY = \"documents\"\n",
    "\n",
    "# Set the model ID and S3 destination prefix for embeddings\n",
    "MODEL_ID = \"twelvelabs.marengo-embed-2-7-v1:0\"\n",
    "S3_DESTINATION_PREFIX = \"embeddings\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f4b1de",
   "metadata": {},
   "source": [
    "## OpenSearch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b5d57",
   "metadata": {},
   "source": [
    "### Load Required Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc4429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "import json\n",
    "\n",
    "from utilities import Utilities\n",
    "\n",
    "from opensearchpy import (\n",
    "    AWSV4SignerAuth,\n",
    "    NotFoundError,\n",
    "    OpenSearch,\n",
    "    RequestsHttpConnection,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68da6c0",
   "metadata": {},
   "source": [
    "### Option #1: Amazon OpenSearch Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d0c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create OpenSearch client for Amazon OpenSearch Serverless\n",
    "# https://opensearch.org/docs/latest/clients/python-low-level/#connecting-to-amazon-opensearch-serverless\n",
    "\n",
    "service = \"aoss\"\n",
    "credentials = boto3.Session(\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    aws_session_token=AWS_SESSION_TOKEN,\n",
    "    region_name=AWS_REGION,\n",
    ").get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, AWS_REGION, service)\n",
    "\n",
    "os_client = OpenSearch(\n",
    "    hosts=[{\"host\": OPENSEARCH_ENDPOINT, \"port\": 443}],\n",
    "    http_auth=auth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    pool_maxsize=20,\n",
    ")\n",
    "\n",
    "os_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda68058",
   "metadata": {},
   "source": [
    "### Option #2: OpenSearch Client Running in Docker\n",
    "\n",
    "Recommended for local development and debugging purposes only as an alternative to Amazon OpenSearch Serverless.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c5396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress security warnings related to unverified HTTPS requests and SSL connections\n",
    "warnings.filterwarnings(\"ignore\", message=\"Unverified HTTPS request\")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", message=\"Connecting to https://localhost:9200 using SSL\"\n",
    ")\n",
    "\n",
    "os_client = OpenSearch(\n",
    "    hosts=[{\"host\": OPENSEARCH_ENDPOINT, \"port\": 9200}],\n",
    "    http_auth=(\"admin\", \"OpenSearch123\"),\n",
    "    use_ssl=True,\n",
    "    verify_certs=False,\n",
    ")\n",
    "\n",
    "os_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b041a8e4",
   "metadata": {},
   "source": [
    "### Create New OpenSearch Vector Index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee1186c",
   "metadata": {},
   "source": [
    "#### Optionally: Delete Existing Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62faa230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_index(os_client, os_index: str) -> None:\n",
    "    \"\"\"Delete an index in OpenSearch.\n",
    "\n",
    "    Args:\n",
    "        os_client (OpenSearch): The OpenSearch client instance.\n",
    "        os_index (str): The name of the index to delete.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os_client.indices.exists(index=os_index):\n",
    "            print(f\"Index '{os_index}' does not exist.\")\n",
    "        else:\n",
    "            os_client.indices.delete(index=os_index)\n",
    "            print(f\"Index '{os_index}' deleted successfully.\")\n",
    "    except ConnectionError as e:\n",
    "        print(f\"Connection error while deleting index '{os_index}': {e}\")\n",
    "\n",
    "\n",
    "# Delete the OpenSearch index for video embeddings\n",
    "delete_index(os_client, INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9841fc9",
   "metadata": {},
   "source": [
    "#### Create New Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a8043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.opensearch.org/docs/latest/vector-search/specialized-operations/nested-search-knn/\n",
    "\n",
    "\n",
    "def create_index(os_client, os_index: str) -> None:\n",
    "    \"\"\"Create an index in OpenSearch with specified settings and mappings.\n",
    "\n",
    "    Args:\n",
    "        os_client (OpenSearch): The OpenSearch client instance.\n",
    "        os_index (str): The name of the index to create.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Define the index settings and mappings\n",
    "    index_body = {\n",
    "        \"settings\": {\n",
    "            \"index\": {\n",
    "                \"knn\": True,\n",
    "                \"number_of_shards\": 2,\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"embeddings\": {\n",
    "                    \"type\": \"nested\",\n",
    "                    \"properties\": {\n",
    "                        \"embedding\": {\n",
    "                            \"type\": \"knn_vector\",\n",
    "                            \"dimension\": 1024,\n",
    "                            \"method\": {\n",
    "                                \"engine\": \"faiss\",\n",
    "                                \"name\": \"hnsw\",\n",
    "                                \"space_type\": \"cosinesimil\",  # Use l2 for Amazon OpenSearch Serverless\n",
    "                            },\n",
    "                        }\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Check if the index already exists\n",
    "    if os_client.indices.exists(index=os_index):\n",
    "        print(f\"Index '{os_index}' already exists.\")\n",
    "    else:\n",
    "        os_client.indices.create(index=os_index, body=index_body)\n",
    "        print(f\"Index '{os_index}' created successfully.\")\n",
    "\n",
    "\n",
    "# Create the OpenSearch index for video embeddings\n",
    "create_index(os_client, INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780b360e",
   "metadata": {},
   "source": [
    "#### Retrieve Information About OpenSearch Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef4663",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = os_client.indices.get(index=INDEX_NAME)\n",
    "    print(json.dumps(response, indent=4))\n",
    "except NotFoundError as ex:\n",
    "    print(f\"Index not found: {ex}\")\n",
    "except Exception as ex:\n",
    "    print(ex.error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad06a2f",
   "metadata": {},
   "source": [
    "### Bulk Index OpenSearch Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10219d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_index_documents(os_index: str, document_path: str) -> None:\n",
    "    \"\"\"Load documents from JSON files in the specified directory and index them in OpenSearch.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The name of the OpenSearch index to create or use.\n",
    "        document_path (str): Directory containing the document JSON files\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    payload = \"\"\n",
    "    put_command = f'{{ \"create\": {{ \"_index\": \"{os_index}\" }} }}\\n'\n",
    "\n",
    "    for file in os.listdir(document_path):\n",
    "        if file.endswith(\".json\"):\n",
    "            with open(os.path.join(document_path, file), \"r\") as f:\n",
    "                tmp = json.load(f)\n",
    "                payload += f\"{put_command}{json.dumps(tmp)}\\n\"\n",
    "    try:\n",
    "        response = os_client.bulk(\n",
    "            index=os_index,\n",
    "            body=payload,\n",
    "        )\n",
    "        print(json.dumps(response, indent=4))\n",
    "        row_count = int(len(payload.splitlines()) / 2)\n",
    "        return row_count\n",
    "    except Exception as ex:\n",
    "        print(f\"Error indexing documents: {ex}\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "if not os.path.exists(DOCUMENT_DIRECTORY):\n",
    "    print(\n",
    "        f\"Document directory '{DOCUMENT_DIRECTORY}' does not exist, skipping indexing.\"\n",
    "    )\n",
    "else:\n",
    "    row_count = load_and_index_documents(INDEX_NAME, DOCUMENT_DIRECTORY)\n",
    "    print(f\"Total rows to index: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df0e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "# Wait for Amazon OpenSearch Serverless indexing to complete and refresh (~60s)\n",
    "response = os_client.count(index=INDEX_NAME)\n",
    "while response[\"count\"] != row_count:\n",
    "    response = os_client.count(index=INDEX_NAME)\n",
    "    print(f\"Current indexed documents: {response['count']}\")\n",
    "    sleep(10)\n",
    "print(f\"Indexing completed. Total indexed documents: {response['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80085f1c",
   "metadata": {},
   "source": [
    "## Query the Amazon OpenSearch Index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ee0925",
   "metadata": {},
   "source": [
    "### Convert User Text Query to Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def generate_search_embedding(client: boto3.client, search_text) -> dict:\n",
    "    \"\"\"Generates an embedding for a search query using the Bedrock service.\n",
    "    Args:\n",
    "        client (boto3.client): The Boto3 client for the Bedrock service.\n",
    "    Returns:\n",
    "        dict: The response from the video analysis job.\n",
    "    \"\"\"\n",
    "    response = client.start_async_invoke(\n",
    "        modelId=MODEL_ID,\n",
    "        modelInput={\n",
    "            \"inputType\": \"text\",\n",
    "            \"inputText\": search_text,\n",
    "        },\n",
    "        outputDataConfig={\n",
    "            \"s3OutputDataConfig\": {\n",
    "                \"s3Uri\": f\"s3://{S3_VIDEO_STORAGE_BUCKET_MARENGO}/{S3_DESTINATION_PREFIX}/\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def download_search_embedding_from_s3(client: boto3.client, s3_key: str) -> dict:\n",
    "    \"\"\"Download the output file from S3 and save it locally.\n",
    "    Args:\n",
    "        client (boto3.client): The Boto3 S3 client.\n",
    "        s3_key (str): The S3 key of the output file.\n",
    "    Returns:\n",
    "        VideoEmbeddings: The video embedding object.\n",
    "    \"\"\"\n",
    "    s3_object = client.get_object(\n",
    "        Bucket=S3_VIDEO_STORAGE_BUCKET_MARENGO,\n",
    "        Key=s3_key,\n",
    "    )\n",
    "    embedding = json.loads(s3_object[\"Body\"].read().decode(\"utf-8\"))\n",
    "\n",
    "    return embedding\n",
    "\n",
    "\n",
    "# Instantiate the Boto3 clients\n",
    "config = Config(\n",
    "    retries={\n",
    "        \"max_attempts\": 5,\n",
    "        \"mode\": \"standard\",  # Or 'adaptive' for a more sophisticated approach\n",
    "    }\n",
    ")\n",
    "\n",
    "bedrock_runtime_client = boto3.client(\n",
    "    service_name=\"bedrock-runtime\", region_name=AWS_REGION, config=config\n",
    ")\n",
    "\n",
    "s3_client = boto3.client(\"s3\", region_name=AWS_REGION)\n",
    "\n",
    "# Generate embeddings for the video\n",
    "# search_text = \"boom boom boom to the bassline\"\n",
    "search_text = \"cars driving in a city\"\n",
    "response = generate_search_embedding(bedrock_runtime_client, search_text)\n",
    "\n",
    "# Wait for the job to complete\n",
    "print(f\"Job started with invocation ARN: {response['invocationArn'].split(\"/\")[-1]}\")\n",
    "invocation_arn = response[\"invocationArn\"]\n",
    "final_job_status = Utilities.poll_job_status(bedrock_runtime_client, invocation_arn)\n",
    "print(f\"Final job status: {final_job_status}\")\n",
    "\n",
    "# Download the output file from S3\n",
    "s3_prefix = invocation_arn.split(\"/\")[-1]\n",
    "s3_key = f\"{S3_DESTINATION_PREFIX}/{s3_prefix}/output.json\"\n",
    "text_embedding = download_search_embedding_from_s3(s3_client, s3_key)\n",
    "\n",
    "text_embedding = text_embedding[\"data\"][0][\"embedding\"]\n",
    "print(f\"Embedding: {text_embedding[:5]}...\")  # Print first 5 elements for brevity\n",
    "\n",
    "# Optionally save the text embedding to a JSON file for later use\n",
    "with open(\"text_embedding.json\", \"w\") as f:\n",
    "    json.dump(text_embedding, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Reload the embeddings from JSON files instead of calling the API repeatedly.\n",
    "# This can be useful for offline use or debugging and testing purposes.\n",
    "\n",
    "text_embedding = json.load(open(\"text_embedding.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4601932b",
   "metadata": {},
   "source": [
    "### Nested k-NN Semantic Search (Approximate k-NN Search (ANN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d698c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://docs.opensearch.org/docs/latest/vector-search/vector-search-techniques/approximate-knn/#get-started-with-approximate-k-nn\n",
    "\n",
    "\n",
    "def semantic_search(os_index: str, embedding: list) -> dict:\n",
    "    \"\"\"Query the OpenSearch index using a text embedding.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The ID of the Amazon OpenSearch index.\n",
    "        embedding (list): The embedding vector to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The search response from OpenSearch.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"embeddings\",\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"embeddings.embedding\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"k\": 6,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"size\": 6,\n",
    "        \"_source\": {\"excludes\": [\"embeddings.embedding\"]},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_results = os_client.search(body=query, index=os_index)\n",
    "        return search_results\n",
    "    except Exception as ex:\n",
    "        print(f\"Error querying index: {ex}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Query the index with the embedding\n",
    "search_results_1 = semantic_search(INDEX_NAME, text_embedding)\n",
    "\n",
    "for hit in search_results_1[\"hits\"][\"hits\"]:\n",
    "    print(f\"Video ID: {hit['_source']['videoName']}\")\n",
    "    print(f\"Title: {hit['_source']['title']}\")\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"Duration: {hit['_source']['durationSec']:.2f} seconds\")\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2598e3",
   "metadata": {},
   "source": [
    "### Nested k-NN Semantic Search with Filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08bf6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://docs.opensearch.org/docs/latest/vector-search/filter-search-knn/efficient-knn-filtering/\n",
    "\n",
    "\n",
    "def semantic_search_with_filter(os_index: str, embedding: list) -> dict:\n",
    "    \"\"\"Query the OpenSearch index using a text embedding with a filter on segment duration.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The ID of the Amazon OpenSearch index.\n",
    "        embedding (list): The embedding vector to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The search response from OpenSearch.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"embeddings\",\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"embeddings.embedding\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"k\": 6,\n",
    "                            \"filter\": {\n",
    "                                \"bool\": {\n",
    "                                    \"must\": [\n",
    "                                        {\n",
    "                                            \"range\": {\n",
    "                                                \"durationSec\": {\n",
    "                                                    \"gte\": 20,\n",
    "                                                    \"lte\": 60,\n",
    "                                                }\n",
    "                                            }\n",
    "                                        },\n",
    "                                    ]\n",
    "                                }\n",
    "                            },\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"size\": 6,\n",
    "        \"_source\": {\"excludes\": [\"embeddings.embedding\"]},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_results = os_client.search(body=query, index=os_index)\n",
    "        return search_results\n",
    "    except Exception as ex:\n",
    "        print(f\"Error querying index: {ex}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Query the index with the embedding\n",
    "search_results_2 = semantic_search_with_filter(INDEX_NAME, text_embedding)\n",
    "\n",
    "for hit in search_results_2[\"hits\"][\"hits\"]:\n",
    "    print(f\"Video ID: {hit['_source']['videoName']}\")\n",
    "    print(f\"Title: {hit['_source']['title']}\")\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"Duration: {hit['_source']['durationSec']:.2f} seconds\")\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb548f93",
   "metadata": {},
   "source": [
    "### Nested k-NN Semantic Search with Inner Hits\n",
    "\n",
    "Include information about the matching nested fields in the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee98102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://docs.opensearch.org/docs/latest/vector-search/specialized-operations/nested-search-knn/#inner-hits\n",
    "\n",
    "\n",
    "def semantic_search_inner_hits(os_index: str, embedding: list) -> dict:\n",
    "    \"\"\"Query the OpenSearch index using a text embedding with inner hits to retrieve nested segments.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The ID of the Amazon OpenSearch index.\n",
    "        embedding (list): The embedding vector to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The search response from OpenSearch.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"embeddings\",\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"embeddings.embedding\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"k\": 6,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"inner_hits\": {\n",
    "                    \"_source\": False,\n",
    "                    \"fields\": [\n",
    "                        \"embeddings.startSec\",\n",
    "                        \"embeddings.endSec\",\n",
    "                        \"embeddings.embeddingOption\",\n",
    "                    ],\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"size\": 6,\n",
    "        \"_source\": {\"excludes\": [\"embeddings.embedding\"]},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_results = os_client.search(body=query, index=os_index)\n",
    "        return search_results\n",
    "    except Exception as ex:\n",
    "        print(f\"Error querying index: {ex}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Query the index with the embedding\n",
    "search_results_3 = semantic_search_inner_hits(INDEX_NAME, text_embedding)\n",
    "print(search_results_3)\n",
    "for hit in search_results_3[\"hits\"][\"hits\"]:\n",
    "    print(f\"Video ID: {hit['_source']['videoName']}\")\n",
    "    print(f\"Title: {hit['_source']['title']}\")\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"Duration: {hit['_source']['durationSec']:.2f} seconds\")\n",
    "    print(\"Matching Segment:\")\n",
    "    for segment in hit[\"inner_hits\"][\"embeddings\"][\"hits\"][\"hits\"]:\n",
    "        print(f\"  Segment: {segment['_nested']['offset']}\")\n",
    "        print(f\"    Score: {segment['_score']}\")\n",
    "        print(\n",
    "            f\"    Embedding type: {segment['fields']['embeddings.embeddingOption'][0]}\"\n",
    "        )\n",
    "        print(f\"    Start: {segment['fields']['embeddings.startSec'][0]} seconds\")\n",
    "        print(f\"    End: {segment['fields']['embeddings.endSec'][0]} seconds\")\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6dd1e6",
   "metadata": {},
   "source": [
    "### Nested k-NN Semantic Search with all Nested Hits\n",
    "\n",
    "To retrieve the scores for all nested field documents within each parent document. By default, only the highest-scoring nested document is considered when you query nested fields.\n",
    "\n",
    "_Note that as of 2025-06-28, although Amazon OpenSearch Serverless claims that it supports version 2.19, the `expand_nested_docs` is not available (error: `Error querying index: RequestError(400, 'x_content_parse_exception', '[1:12885] [knn] unknown field [expand_nested_docs]')`). The below search was performed in OpenSearch using Docker._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82983df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://docs.opensearch.org/docs/latest/vector-search/specialized-operations/nested-search-knn/#retrieving-all-nested-hits\n",
    "\n",
    "\n",
    "def semantic_search_all_inner_hits(os_index: str, embedding: list) -> dict:\n",
    "    \"\"\"Query the OpenSearch index using a text embedding with inner hits to retrieve all matching nested segments.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The ID of the Amazon OpenSearch index.\n",
    "        embedding (list): The embedding vector to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The search response from OpenSearch.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"embeddings\",\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"embeddings.embedding\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"k\": 6,\n",
    "                            \"expand_nested_docs\": True,\n",
    "                            \"rescore\": True,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"inner_hits\": {\n",
    "                    \"_source\": False,\n",
    "                    \"fields\": [\n",
    "                        \"embeddings.startSec\",\n",
    "                        \"embeddings.endSec\",\n",
    "                        \"embeddings.embeddingOption\",\n",
    "                    ],\n",
    "                    \"size\": 3,\n",
    "                },\n",
    "                \"score_mode\": \"max\",\n",
    "            }\n",
    "        },\n",
    "        \"size\": 6,\n",
    "        \"_source\": {\"excludes\": [\"embeddings.embedding\"]},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_results = os_client.search(body=query, index=os_index)\n",
    "        return search_results\n",
    "    except Exception as ex:\n",
    "        print(f\"Error querying index: {ex}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Query the index with the embedding\n",
    "search_results_4 = semantic_search_all_inner_hits(INDEX_NAME, text_embedding)\n",
    "for hit in search_results_4[\"hits\"][\"hits\"]:\n",
    "    print(f\"Video ID: {hit['_source']['videoName']}\")\n",
    "    print(f\"Title: {hit['_source']['title']}\")\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"Duration: {hit['_source']['durationSec']:.2f} seconds\")\n",
    "    print(\"Matching Segments:\")\n",
    "    for segment in hit[\"inner_hits\"][\"embeddings\"][\"hits\"][\"hits\"]:\n",
    "        print(f\"  Segment: {segment['_nested']['offset']}\")\n",
    "        print(f\"    Score: {segment['_score']}\")\n",
    "        print(\n",
    "            f\"    Embedding type: {segment['fields']['embeddings.embeddingOption'][0]}\"\n",
    "        )\n",
    "        print(f\"    Start: {segment['fields']['embeddings.startSec'][0]} seconds\")\n",
    "        print(f\"    End: {segment['fields']['embeddings.endSec'][0]} seconds\")\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407054ef",
   "metadata": {},
   "source": [
    "### Nested k-NN Semantic Search with all Nested Hits, with Filtering on Nested Fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a62aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://docs.opensearch.org/docs/latest/vector-search/specialized-operations/nested-search-knn/#retrieving-all-nested-hits\n",
    "\n",
    "\n",
    "def semantic_search_all_inner_hits(os_index: str, embedding: list) -> dict:\n",
    "    \"\"\"Query the OpenSearch index using a text embedding with inner hits to retrieve all matching nested segments.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The ID of the Amazon OpenSearch index.\n",
    "        embedding (list): The embedding vector to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The search response from OpenSearch.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"embeddings\",\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"embeddings.embedding\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"k\": 6,\n",
    "                            \"expand_nested_docs\": True,\n",
    "                            \"filter\": {\"term\": {\"embeddings.embeddingOption\": \"audio\"}},\n",
    "                            \"rescore\": True,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"inner_hits\": {\n",
    "                    \"_source\": False,\n",
    "                    \"fields\": [\n",
    "                        \"embeddings.startSec\",\n",
    "                        \"embeddings.endSec\",\n",
    "                        \"embeddings.embeddingOption\",\n",
    "                    ],\n",
    "                },\n",
    "                \"score_mode\": \"max\",\n",
    "            }\n",
    "        },\n",
    "        \"size\": 6,\n",
    "        \"_source\": {\"excludes\": [\"embeddings.embedding\"]},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_results = os_client.search(body=query, index=os_index)\n",
    "        return search_results\n",
    "    except Exception as ex:\n",
    "        print(f\"Error querying index: {ex}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Query the index with the embedding\n",
    "search_results_5 = semantic_search_all_inner_hits(INDEX_NAME, text_embedding)\n",
    "for hit in search_results_5[\"hits\"][\"hits\"]:\n",
    "    print(f\"Video ID: {hit['_source']['videoName']}\")\n",
    "    print(f\"Title: {hit['_source']['title']}\")\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"Duration: {hit['_source']['durationSec']:.2f} seconds\")\n",
    "    print(\"Matching Segments:\")\n",
    "    for segment in hit[\"inner_hits\"][\"embeddings\"][\"hits\"][\"hits\"]:\n",
    "        print(f\"  Segment: {segment['_nested']['offset']}\")\n",
    "        print(f\"    Score: {segment['_score']}\")\n",
    "        print(\n",
    "            f\"    Embedding type: {segment['fields']['embeddings.embeddingOption'][0]}\"\n",
    "        )\n",
    "        print(f\"    Start: {segment['fields']['embeddings.startSec'][0]} seconds\")\n",
    "        print(f\"    End: {segment['fields']['embeddings.endSec'][0]} seconds\")\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8862b659",
   "metadata": {},
   "source": [
    "### Radial Search\n",
    "\n",
    "Search all points within a vector space that reside within a specified maximum distance or minimum score threshold from a query point (squared Euclidean distance).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae3af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://docs.opensearch.org/docs/latest/vector-search/specialized-operations/radial-search-knn/\n",
    "\n",
    "\n",
    "def radial_search(os_index: str, embedding: list) -> dict:\n",
    "    \"\"\"Query the OpenSearch index using a text embedding with radial search to find segments within a certain distance.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The ID of the Amazon OpenSearch index.\n",
    "        embedding (list): The embedding vector to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The search response from OpenSearch.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"embeddings\",\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"embeddings.embedding\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"max_distance\": 1,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"size\": 6,\n",
    "        \"_source\": {\"excludes\": [\"embeddings.embedding\"]},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_results = os_client.search(body=query, index=os_index)\n",
    "        return search_results\n",
    "    except Exception as ex:\n",
    "        print(f\"Error querying index: {ex}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Query the index with the embedding\n",
    "search_results_6 = semantic_search(INDEX_NAME, text_embedding)\n",
    "\n",
    "for hit in search_results_6[\"hits\"][\"hits\"]:\n",
    "    print(f\"Video ID: {hit['_source']['videoName']}\")\n",
    "    print(f\"Title: {hit['_source']['title']}\")\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"Duration: {hit['_source']['durationSec']:.2f} seconds\")\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2103e",
   "metadata": {},
   "source": [
    "## Displaying Previews of Search Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e98dd5",
   "metadata": {},
   "source": [
    "### Visual Grid of Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7934d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from urllib import request\n",
    "import io\n",
    "\n",
    "\n",
    "def load_image_from_url(url: str) -> Image.Image:\n",
    "    \"\"\"Load an image from a URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the image to load.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image.Image: The loaded image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with request.urlopen(url) as response:\n",
    "            image_data = response.read()\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "            return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading video thumbnail from URL: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "index = 1\n",
    "rows = 3\n",
    "columns = 3\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "for hit in search_results_1[\"hits\"][\"hits\"]:\n",
    "    fig.set_dpi(300)\n",
    "    fig.add_subplot(rows, columns, index)\n",
    "    image_url = hit[\"_source\"][\"keyframeURL\"]\n",
    "    image = load_image_from_url(image_url)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image)\n",
    "    plt.title(\n",
    "        f'Video: {hit[\"_source\"][\"videoName\"][0:40]}\\nScore: {hit[\"_score\"]}',\n",
    "        fontdict=dict(family=\"Arial\", size=8),\n",
    "        color=\"black\",\n",
    "    )\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250733bf",
   "metadata": {},
   "source": [
    "### 2D/3D Visualizations Using t-SNE\n",
    "\n",
    "t-SNE (t-distributed Stochastic Neighbor Embedding) is a popular technique for reducing high-dimensional data, such as embeddings, to 2 or 3 dimensions for visualization or further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4eba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search_t_sne(os_index: str, embedding: list) -> dict:\n",
    "    \"\"\"Query the OpenSearch index using a text embedding.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The ID of the Amazon OpenSearch index.\n",
    "        embedding (list): The embedding vector to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The search response from OpenSearch including embeddings.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"embeddings\",\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"embeddings.embedding\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"k\": 9,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"inner_hits\": {\n",
    "                    \"_source\": False,\n",
    "                    \"fields\": [\n",
    "                        \"embeddings.startSec\",\n",
    "                        \"embeddings.endSec\",\n",
    "                        \"embeddings.embeddingOption\",\n",
    "                    ],\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"size\": 9,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_results = os_client.search(body=query, index=os_index)\n",
    "        return search_results\n",
    "    except Exception as ex:\n",
    "        print(f\"Error querying index: {ex}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Query the index with the embedding\n",
    "search_results_7 = semantic_search_t_sne(INDEX_NAME, text_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings and video names from the search results\n",
    "results = []\n",
    "\n",
    "for hit in search_results_7[\"hits\"][\"hits\"]:\n",
    "    results.append(\n",
    "        [\n",
    "            hit[\"_source\"][\"embeddings\"][0][\"embedding\"],\n",
    "            hit[\"_source\"][\"videoName\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "results.append([text_embedding, \"User query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9e165b",
   "metadata": {},
   "source": [
    "#### 2D Visualization Using t-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97164d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "# Initialize t-SNE (n_components=2 for 2D reduction)\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=5)\n",
    "\n",
    "# Extract embeddings and apply t-SNE\n",
    "embeddings = np.array([res[0] for res in results])\n",
    "embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Combine the reduced embeddings with their corresponding video names\n",
    "vis_dims_2d = list(\n",
    "    map(\n",
    "        lambda x: [x[0][0], x[0][1], x[1]], zip(embeddings, [res[1] for res in results])\n",
    "    )\n",
    ")\n",
    "print(vis_dims_2d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8061da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Search results\n",
    "for i, video_name in enumerate(vis_dims_2d[0:-1]):\n",
    "    x = np.array([vis_dims_2d[i][0]])\n",
    "    y = np.array([vis_dims_2d[i][1]])\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=15,\n",
    "                colorscale=\"Viridis\",\n",
    "                opacity=1.0,\n",
    "                symbol=\"circle\",\n",
    "            ),\n",
    "            name=vis_dims_2d[i][2][0:25],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # User query\n",
    "    x = np.array([vis_dims_2d[-1][0]])\n",
    "    y = np.array([vis_dims_2d[-1][1]])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        mode=\"text+markers\",\n",
    "        marker=dict(\n",
    "            size=15,\n",
    "            color=\"black\",\n",
    "            colorscale=\"Viridis\",\n",
    "            opacity=1.0,\n",
    "            symbol=\"square\",\n",
    "        ),\n",
    "        name=vis_dims_2d[-1][2][0:25],\n",
    "        text=vis_dims_2d[-1][2],\n",
    "        textposition=\"bottom center\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=True,\n",
    "    width=900,\n",
    "    height=600,\n",
    "    font=dict(size=12, color=\"black\", family=\"Arial, sans-serif\"),\n",
    "    title=\"Search Results using t-SNE\",\n",
    "    margin=dict(l=30, r=30, b=30, t=60, pad=10),\n",
    "    xaxis=dict(title=\"x\"),\n",
    "    yaxis=dict(title=\"y\"),\n",
    "    legend=dict(title=\"   Search Results\"),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5160c095",
   "metadata": {},
   "source": [
    "#### 3D Visualization Using t-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "# Initialize t-SNE (n_components=3 for 3D reduction)\n",
    "tsne = TSNE(n_components=3, random_state=42, perplexity=5)\n",
    "\n",
    "# Extract embeddings and apply t-SNE\n",
    "embeddings = np.array([res[0] for res in results])\n",
    "embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Combine the reduced embeddings with their corresponding video names\n",
    "vis_dims_3d = list(\n",
    "    map(\n",
    "        lambda x: [x[0][0], x[0][1], x[0][2], x[1]],\n",
    "        zip(embeddings, [res[1] for res in results]),\n",
    "    )\n",
    ")\n",
    "print(vis_dims_3d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95902df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Results\n",
    "for i, video_name in enumerate(vis_dims_3d[0:-1]):\n",
    "    x = np.array([vis_dims_3d[i][0]])\n",
    "    y = np.array([vis_dims_3d[i][1]])\n",
    "    z = np.array([vis_dims_3d[i][2]])\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            z=z,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=7, colorscale=\"Viridis\", opacity=1.0, symbol=\"circle\"),\n",
    "            name=vis_dims_3d[i][3][0:25],\n",
    "            text=vis_dims_3d[i][3][0:25],\n",
    "            textposition=\"top center\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # User query\n",
    "    x = np.array([vis_dims_3d[-1][0]])\n",
    "    y = np.array([vis_dims_3d[-1][1]])\n",
    "    z = np.array([vis_dims_3d[-1][2]])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        z=z,\n",
    "        mode=\"markers\",\n",
    "        marker=dict(\n",
    "            size=7, color=\"black\", colorscale=\"Viridis\", opacity=1.0, symbol=\"square\"\n",
    "        ),\n",
    "        name=vis_dims_3d[-1][3],\n",
    "        text=vis_dims_3d[-1][3],\n",
    "        textposition=\"top center\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "x_eye = -1.25\n",
    "y_eye = 1.5\n",
    "z_eye = 0.5\n",
    "\n",
    "fig.update_layout(\n",
    "    # autosize=True,\n",
    "    width=900,\n",
    "    height=600,\n",
    "    font=dict(size=12, color=\"black\", family=\"Arial, sans-serif\"),\n",
    "    title=\"Search Results using t-SNE\",\n",
    "    margin=dict(l=30, r=30, b=30, t=50, pad=10),\n",
    "    scene=dict(\n",
    "        xaxis=dict(title=\"z\"),\n",
    "        yaxis=dict(title=\"x\"),\n",
    "        zaxis=dict(title=\"y\"),\n",
    "    ),\n",
    "    scene_camera_eye=dict(x=x_eye, y=y_eye, z=z_eye),\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            showactive=True,\n",
    "            y=0.9,\n",
    "            x=0.9,\n",
    "            xanchor=\"left\",\n",
    "            yanchor=\"bottom\",\n",
    "            pad=dict(t=10, r=10),\n",
    "            buttons=[\n",
    "                dict(\n",
    "                    label=\"Play\",\n",
    "                    method=\"animate\",\n",
    "                    args=[\n",
    "                        None,\n",
    "                        dict(\n",
    "                            frame=dict(duration=15, redraw=True),\n",
    "                            transition=dict(duration=1),\n",
    "                            fromcurrent=True,\n",
    "                            mode=\"immediate\",\n",
    "                        ),\n",
    "                    ],\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    "    legend=dict(\n",
    "        title=\"   Search Results\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def rotate_z(x, y, z, theta):\n",
    "    w = x + 1j * y\n",
    "    return np.real(np.exp(1j * theta) * w), np.imag(np.exp(1j * theta) * w), z\n",
    "\n",
    "\n",
    "frames = []\n",
    "for t in np.arange(0, 10, 0.01):\n",
    "    xe, ye, ze = rotate_z(x_eye, y_eye, z_eye, -t)\n",
    "    frames.append(go.Frame(layout=dict(scene_camera_eye=dict(x=xe, y=ye, z=ze))))\n",
    "fig.frames = frames\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15a34ab",
   "metadata": {},
   "source": [
    "### Extracting a List of Segments from Video Search Results\n",
    "\n",
    "Reorder the search results as a list of segments as opposed to a list of videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da1bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://docs.opensearch.org/docs/latest/vector-search/specialized-operations/nested-search-knn/#retrieving-all-nested-hits\n",
    "\n",
    "\n",
    "def semantic_search_all_inner_hits(os_index: str, embedding: list) -> dict:\n",
    "    \"\"\"Query the OpenSearch index using a text embedding with inner hits to retrieve all matching nested segments.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The ID of the Amazon OpenSearch index.\n",
    "        embedding (list): The embedding vector to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The search response from OpenSearch.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"embeddings\",\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"embeddings.embedding\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"k\": 50,\n",
    "                            \"expand_nested_docs\": True,\n",
    "                            \"rescore\": True,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"inner_hits\": {\n",
    "                    \"_source\": False,\n",
    "                    \"fields\": [\n",
    "                        \"embeddings.startSec\",\n",
    "                        \"embeddings.endSec\",\n",
    "                        \"embeddings.embeddingOption\",\n",
    "                        \"embeddings.embedding\",\n",
    "                    ],\n",
    "                    \"size\": 100,\n",
    "                },\n",
    "                \"score_mode\": \"max\",\n",
    "            }\n",
    "        },\n",
    "        \"size\": 50,\n",
    "        # \"_source\": {\"excludes\": [\"embeddings.embedding\"]},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_results = os_client.search(body=query, index=os_index)\n",
    "        return search_results\n",
    "    except Exception as ex:\n",
    "        print(f\"Error querying index: {ex}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Query the index with the embedding\n",
    "search_results_8 = semantic_search_all_inner_hits(INDEX_NAME, text_embedding)\n",
    "\n",
    "for hit in search_results_8[\"hits\"][\"hits\"]:\n",
    "    print(f\"Video ID: {hit['_source']['videoName']}\")\n",
    "    print(f\"Title: {hit['_source']['title']}\")\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"Duration: {hit['_source']['durationSec']:.2f} seconds\")\n",
    "    print(\"Matching Segments:\")\n",
    "    for segment in hit[\"inner_hits\"][\"embeddings\"][\"hits\"][\"hits\"]:\n",
    "        print(f\"  Segment: {segment['_nested']['offset']}\")\n",
    "        print(f\"    Score: {segment['_score']}\")\n",
    "        print(\n",
    "            f\"    Embedding type: {segment['fields']['embeddings.embeddingOption'][0]}\"\n",
    "        )\n",
    "        print(f\"    Start: {segment['fields']['embeddings.startSec'][0]} seconds\")\n",
    "        print(f\"    End: {segment['fields']['embeddings.endSec'][0]} seconds\")\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2fd5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segments_sorted_by_score(results: dict) -> list:\n",
    "    \"\"\"Extract segments from search results and sort them by score.\n",
    "\n",
    "    Args:\n",
    "        results (dict): The search results from the OpenSearch query.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of segments sorted by their score in descending order.\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "\n",
    "    for hit in results[\"hits\"][\"hits\"]:\n",
    "        for segment in hit[\"inner_hits\"][\"embeddings\"][\"hits\"][\"hits\"]:\n",
    "            segment_score = {}\n",
    "            segment_score[\"title\"] = hit[\"_source\"][\"title\"]\n",
    "            segment_score[\"videoName\"] = hit[\"_source\"][\"videoName\"]\n",
    "            segment_score[\"offset\"] = segment[\"_nested\"][\"offset\"]\n",
    "            segment_score[\"_score\"] = segment[\"_score\"]\n",
    "            segment_score[\"embedding_option\"] = segment[\"fields\"][\n",
    "                \"embeddings.embeddingOption\"\n",
    "            ][0]\n",
    "            segment_score[\"startSec\"] = round(\n",
    "                segment[\"fields\"][\"embeddings.startSec\"][0], 2\n",
    "            )\n",
    "            segment_score[\"endSec\"] = round(\n",
    "                segment[\"fields\"][\"embeddings.endSec\"][0], 2\n",
    "            )\n",
    "            segment_score[\"embedding\"] = segment[\"fields\"][\"embeddings.embedding\"]\n",
    "            segments.append(segment_score)\n",
    "\n",
    "    segments = sorted(segments, key=lambda x: x[\"_score\"], reverse=True)\n",
    "    # print(json.dumps(segments[:3], indent=4))\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc6910",
   "metadata": {},
   "source": [
    "#### Display Top Video Segment from Search Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b695412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "segments = extract_segments_sorted_by_score(search_results_8)\n",
    "video_file = segments[0][\"videoName\"]\n",
    "segment_start = segments[0][\"startSec\"]\n",
    "segment_end = segments[0][\"endSec\"]\n",
    "\n",
    "HTML(\n",
    "    f\"\"\"\n",
    "    <h2>Segment Details</h2>\n",
    "    <p>Filename: {video_file}</p>\n",
    "    <p>Segment start: {segment_start} seconds</p>\n",
    "    <p>Segment end: {segment_end} seconds</p>\n",
    "    <video width=\"600\" height=\"auto\" controls>\n",
    "        <source src=\"videos//{video_file}#t={segment_start},{segment_end}\" type=\"video/mp4\">\n",
    "    </video>    \n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c54ca0",
   "metadata": {},
   "source": [
    "#### Display All Segments in 2D Scatter Plot Using PCA\n",
    "\n",
    "Principal Component Analysis (PCA) is a dimensionality reduction technique used to simplify complex datasets by transforming the original variables into a new set of uncorrelated variables called principal components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e9827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Extract segments and their embeddings from the search results\n",
    "segments = extract_segments_sorted_by_score(search_results_8)\n",
    "embeddings = list(map(lambda segment: segment[\"embedding\"], segments))\n",
    "\n",
    "# Reduce the dense vector embedding's dimensions from 1,024 to 2 using PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit the PCA model to the embeddings and transform them to 2D\n",
    "vis_dims_2d = pca.fit_transform(embeddings)\n",
    "print(f\"Reduced dimensions shape (2d): {vis_dims_2d.shape}\")\n",
    "\n",
    "# Find clusters using KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(vis_dims_2d)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Create a new list of segments with the 2D embeddings\n",
    "segments = list(\n",
    "    map(\n",
    "        lambda segment, vis_dim: {**segment, \"embedding\": vis_dim},\n",
    "        segments,\n",
    "        vis_dims_2d,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = px.scatter(\n",
    "    segments,\n",
    "    x=[segment[\"embedding\"][0] for segment in segments],\n",
    "    y=[segment[\"embedding\"][1] for segment in segments],\n",
    "    color=[segment[\"videoName\"] for segment in segments],\n",
    "    hover_name=[segment[\"videoName\"] for segment in segments],\n",
    "    hover_data=[\"embedding_option\", \"startSec\", \"endSec\", \"offset\"],\n",
    "    title=\"All Commercial Segments using PCA\",\n",
    "    labels={\"x\": \"PCA Dimension 1\", \"y\": \"PCA Dimension 2\"},\n",
    "    width=900,\n",
    "    height=600,\n",
    "    opacity=0.75,\n",
    ")\n",
    "\n",
    "fig.layout.xaxis.scaleanchor = \"y\"\n",
    "fig.layout.yaxis.scaleanchor = \"x\"\n",
    "fig.layout.xaxis.scaleratio = 1\n",
    "fig.layout.yaxis.scaleratio = 1\n",
    "fig.layout.xaxis.dtick = 0.25\n",
    "fig.layout.yaxis.dtick = 0.25\n",
    "fig.layout.legend = dict(\n",
    "    title_text=\"Embedding Type\",\n",
    "    font=dict(size=10, family=\"Arial, sans-serif\"),\n",
    ")\n",
    "fig.layout.title.font = dict(\n",
    "    size=16,\n",
    "    family=\"Arial, sans-serif\",\n",
    ")\n",
    "fig.layout.showlegend = False\n",
    "\n",
    "# Add circles around clusters\n",
    "for cluster in np.unique(labels):\n",
    "    cluster_points = vis_dims_2d[labels == cluster]\n",
    "    center = cluster_points.mean(axis=0)\n",
    "    radius = np.linalg.norm(cluster_points - center, axis=1).max()\n",
    "    # Define circle bounds (Plotly circles use bounding box)\n",
    "    x0, y0 = center - radius\n",
    "    x1, y1 = center + radius\n",
    "    fig.add_shape(\n",
    "        type=\"circle\",\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        x0=x0,\n",
    "        y0=y0,\n",
    "        x1=x1,\n",
    "        y1=y1,\n",
    "        opacity=0.3,\n",
    "        line=dict(\n",
    "            color=\"black\",\n",
    "            width=1,\n",
    "            dash=\"dot\",  # Optional: change to \"solid\", \"dash\", etc. for different styles\n",
    "        ),\n",
    "        fillcolor=\"rgba(0,0,0,0)\",\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe750cb",
   "metadata": {},
   "source": [
    "#### Display All Segments in 2D Scatter Plot Using t-SNE and k-means clustering\n",
    "\n",
    "t-SNE (t-distributed Stochastic Neighbor Embedding) is a popular technique for reducing high-dimensional data, such as embeddings, to 2 or 3 dimensions for visualization or further analysis.\n",
    "\n",
    "k-means clustering is a popular clustering algorithm that does a good job of grouping spherical data together into distinct groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8eb601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# Extract segments and their embeddings from the search results\n",
    "segments = extract_segments_sorted_by_score(search_results_8)\n",
    "embeddings = list(map(lambda segment: segment[\"embedding\"], segments))\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "# Initialize t-SNE (n_components=2 for 2D reduction)\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "# Fit and transform the embeddings\n",
    "vis_dims_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "print(f\"Reduced dimensions shape (2d): {vis_dims_2d.shape}\")\n",
    "\n",
    "# Find clusters using KMeans\n",
    "kmeans = KMeans(n_clusters=70, random_state=0).fit(vis_dims_2d)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Create a new list of segments with the 2D embeddings\n",
    "segments = list(\n",
    "    map(\n",
    "        lambda segment, vis_dim: {**segment, \"embedding\": vis_dim},\n",
    "        segments,\n",
    "        vis_dims_2d,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = px.scatter(\n",
    "    segments,\n",
    "    x=[segment[\"embedding\"][0] for segment in segments],\n",
    "    y=[segment[\"embedding\"][1] for segment in segments],\n",
    "    color=[segment[\"videoName\"][0:10] for segment in segments],\n",
    "    hover_name=[segment[\"videoName\"] for segment in segments],\n",
    "    hover_data=[\"embedding_option\", \"startSec\", \"endSec\", \"offset\"],\n",
    "    title=\"All Commercial Segments using t-SNE\",\n",
    "    labels={\"x\": \"t-SNE Dimension 1\", \"y\": \"t-SNE Dimension 2\"},\n",
    "    width=900,\n",
    "    height=600,\n",
    "    opacity=0.75,\n",
    ")\n",
    "\n",
    "fig.layout.xaxis.scaleanchor = \"y\"\n",
    "fig.layout.yaxis.scaleanchor = \"x\"\n",
    "fig.layout.xaxis.scaleratio = 1\n",
    "fig.layout.yaxis.scaleratio = 1\n",
    "fig.layout.xaxis.dtick = 5\n",
    "fig.layout.yaxis.dtick = 5\n",
    "fig.layout.legend = dict(\n",
    "    title_text=\"Commercial\",\n",
    "    font=dict(size=10, family=\"Arial, sans-serif\"),\n",
    ")\n",
    "fig.layout.title.font = dict(\n",
    "    size=16,\n",
    "    family=\"Arial, sans-serif\",\n",
    ")\n",
    "fig.layout.showlegend = False\n",
    "\n",
    "\n",
    "# Add circles around clusters\n",
    "for cluster in np.unique(labels):\n",
    "    cluster_points = vis_dims_2d[labels == cluster]\n",
    "    center = cluster_points.mean(axis=0)\n",
    "    radius = np.linalg.norm(cluster_points - center, axis=1).max()\n",
    "    # Define circle bounds (Plotly circles use bounding box)\n",
    "    x0, y0 = center - radius\n",
    "    x1, y1 = center + radius\n",
    "    fig.add_shape(\n",
    "        type=\"circle\",\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        x0=x0,\n",
    "        y0=y0,\n",
    "        x1=x1,\n",
    "        y1=y1,\n",
    "        opacity=0.3,\n",
    "        line=dict(\n",
    "            color=\"black\",\n",
    "            width=1,\n",
    "            dash=\"dot\",  # Optional: change to \"solid\", \"dash\", etc. for different styles\n",
    "        ),\n",
    "        fillcolor=\"rgba(0,0,0,0)\",\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ada0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
